{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ashutosh20037/py.gemini-AI/blob/main/gemini_ai_part1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qjcWFrEuc7Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4db455cd-6532-4970-b638-1e1f154e1b23"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "8# !pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HIYidrgpD-ZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import textwrap\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown"
      ],
      "metadata": {
        "id": "NLFLgPqpvZ1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ouq2MBdJwCg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_markdown(text):\n",
        "  text = text.replace('â€¢', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "txL-TniiwWSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GOOGLE_API_KEY=\"AIzaSyAGOP32zUkSX2Pi5GIrk87Bad8w0q9-Ixg \"\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "9HKcsnbNwhhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1=genai.GenerativeModel('gemini-2.0-flash')\n",
        "\n",
        "ans=model1.generate_content(\"what is gemini ai?\")\n",
        "to_markdown(ans.text)\n"
      ],
      "metadata": {
        "id": "Jrg9qPlgw2gT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 904
        },
        "outputId": "367e2fc0-18d4-4b95-ead7-c67ecf34c947"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> Gemini is Google's most powerful and versatile AI model, designed to be multimodal from the ground up. Here's a breakdown:\n> \n> **Key Features and Characteristics:**\n> \n> *   **Multimodal Native:** Gemini is built to understand and process information from various sources simultaneously, including text, code, audio, images, and video. This contrasts with AI models that are primarily trained on text and then adapted for other modalities.\n> *   **Three Sizes/Versions:**\n>     *   **Gemini Ultra:** The most capable model, intended for highly complex tasks. Used in Bard Advanced and other premium AI experiences.\n>     *   **Gemini Pro:** Designed for a wide range of tasks, striking a balance between performance and efficiency. It is what initially powered Bard.\n>     *   **Gemini Nano:** The smallest and most efficient model, designed for on-device use on smartphones and other devices where processing power is limited.\n> *   **Advanced Reasoning:** Gemini is designed with sophisticated reasoning capabilities, allowing it to handle complex tasks such as:\n>     *   Problem-solving\n>     *   Planning\n>     *   Understanding nuanced information\n> *   **Code Generation and Understanding:** Gemini is proficient in various programming languages (like Python, Java, C++, etc.) and can generate, explain, and debug code.\n> *   **Integration with Google Ecosystem:** Gemini is being integrated across various Google products and services, enhancing their capabilities. Examples:\n>     *   **Search:** Improved search results and understanding of complex queries.\n>     *   **Workspace Apps (Gmail, Docs, Sheets, Slides):** Enhanced productivity features such as content creation, summarization, and task automation.\n>     *   **Android:** On-device AI capabilities through Gemini Nano.\n>     *   **Bard (now Gemini):** Powering the core AI conversational experience.\n> *   **Safety and Responsibility:** Google emphasizes responsible development and deployment of Gemini, including measures to mitigate potential harms, biases, and misuse.\n> \n> **In simpler terms:**\n> \n> Imagine an AI that can understand not just words, but also images, videos, and sound, and can use all of that information together to answer your questions, create content, or solve problems. That's Gemini. It's designed to be more human-like in its understanding and interaction with the world.\n> \n> **Key Applications and Use Cases:**\n> \n> *   **Conversational AI (Chatbots):** Powering more natural and helpful conversations.\n> *   **Content Creation:** Generating text, images, and other types of content.\n> *   **Code Generation and Assistance:** Helping developers write and debug code.\n> *   **Data Analysis:** Extracting insights from complex datasets.\n> *   **Research:** Accelerating scientific discovery by analyzing large amounts of data.\n> *   **Personalized Experiences:** Adapting to user preferences and providing tailored recommendations.\n> \n> **How it differs from other AI models (like GPT-4):**\n> \n> While both Gemini and GPT-4 are advanced language models, they have key differences:\n> \n> *   **Native Multimodality:** Gemini is built from the ground up to be multimodal, while GPT-4 is primarily a text-based model with some multimodal capabilities added later.\n> *   **Integration:** Gemini is deeply integrated into Google's ecosystem, giving it a potential advantage in leveraging Google's vast resources and user data.\n> *   **Specific Strengths:** While both are very powerful, they might have different strengths in specific areas. For example, Gemini's coding abilities are often highlighted.\n> \n> **In summary, Gemini is Google's cutting-edge AI model that is designed to be a versatile and powerful tool for a wide range of applications. Its native multimodality and integration with Google's ecosystem make it a significant advancement in the field of artificial intelligence.**\n"
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL.Image\n",
        "\n",
        "# Replace 'actual/path/to/your/image/download.jpeg' with the actual path to your image file.\n",
        "image_path = 'path/to/your/image.jpg'  # Example: 'images/my_image.jpg'\n",
        "Image = PIL.Image.open(image_path)\n",
        "Image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "HP-rGpNBGepZ",
        "outputId": "fea9c51c-7fc1-4240-8bec-63c048ff7434"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'path/to/your/image.jpg'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-4eaf4cd82036>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Replace 'actual/path/to/your/image/download.jpeg' with the actual path to your image file.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'path/to/your/image.jpg'\u001b[0m  \u001b[0;31m# Example: 'images/my_image.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mImage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3465\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3466\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3467\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'path/to/your/image.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#for m in genai.list_models():\n",
        "#   if 'generateContent' in m.supported_generation_methods:\n",
        "#     print(m.name)"
      ],
      "metadata": {
        "id": "ftz-Pr1f3o5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel('gemini-1.5-flash')"
      ],
      "metadata": {
        "id": "ZdQkYYtzzFe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(img)\n",
        "\n",
        "to_markdown(response.text)"
      ],
      "metadata": {
        "id": "WHHULo9MzRh0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "c9ef1a77-e41d-4bb9-e9b4-eebec8a51418"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'img' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-d83cd03fccdf>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mto_markdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'img' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content([\"solve this math problem step by step in hindi\", img], stream=True)\n",
        "response.resolve()"
      ],
      "metadata": {
        "id": "d5uHqfGvzX5z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "735c432e-66d2-4f5d-845c-218dc51e6a0b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a00d00eb99b1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"solve this math problem step by step in hindi\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "to_markdown(response.text)"
      ],
      "metadata": {
        "id": "g_DGOSYxzfil",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "55b234ce-cb12-4704-da1f-f4a1ba94b420"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'response' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-8a2b00597414>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mto_markdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'response' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-zLSBWgzzmAK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}